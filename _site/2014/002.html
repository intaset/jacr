<!DOCTYPE html>

<html lang="en">

<head>

<meta charset="utf-8">

<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="viewport" content="width=device-width, initial-scale=1">
<title>JACR - Terrain Roughness Identification for High-Speed UGVs</title>
<link href='http://fonts.googleapis.com/css?family=PT+Sans:300,400,400italic,500,600,700,700italic&amp;subset=latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese' rel='stylesheet' type='text/css' />

<link href='http://fonts.googleapis.com/css?family=Antic+Slab:300,400,400italic,500,600,700,700italic&amp;subset=latin,greek-ext,cyrillic,latin-ext,greek,cyrillic-ext,vietnamese' rel='stylesheet' type='text/css' />

<link rel="stylesheet" href="../css/style.css" />

<link href="../css/bootstrap.css" rel="stylesheet">
<link href="../images/icon.ico" rel="shortcut icon" type="image/x-icon">

<!--Goole Analytics Most Visited Article Code-->

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-47353717-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


<!-- Include Most Visited Articles JS Code -->
 <script type="text/javascript" src="mostvisited.js"></script> 

<!-- Include SHARE THIS js sources -->
<script type="text/javascript">var switchTo5x=true;</script>
<script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script>
<script type="text/javascript">stLight.options({publisher: "8f49e037-5155-4595-abc0-d069deae6488", doNotHash: true, doNotCopy: false, hashAddressBar: false, onhover:false});</script>
</head>

<body>

<div id="wrapper">

  <div class="header">

    <div class="container">

      <div class="row">

        <header id="header">
          <div class="logo col-sm-4"><a href="http://avestia.com"><img src="/images/logo.png" alt="Journal" class="img" /></a></div>
          <div class="threemenu col-sm-5">
            <div class="row"><a class="link col-sm-4" href="http://avestia.com"><img src="/images/home.jpg" class="img"></a> <a class="link col-sm-4" href="http://avestia.com/journals/"><img src="/images/journals.jpg" class="img"></a> <a class="link col-sm-4" href="http://amss.avestia.com"><img src="/images/submit.jpg" class="img"></a></div>
          </div>
          <div class="searching col-sm-3">
<div class="sharethis">Share this page:<br/>
<span class='st_email'></span>
<span class='st_facebook'></span>
<span class='st_twitter'></span>
<span class='st_googleplus'></span>
<span class='st_linkedin'></span>
</div>
            
         <div class="search_wrapper">
         <form class="search" action="../results" method="get">
              <fieldset>
                <span class="text">
                <input name="q" id="q" type="text" value="" placeholder="Search..." /><button class="search_top_button">GO</button>
                </span>

              </fieldset>
            </form>
            
            </div>
          </div>
          <div class="col-lg-12">

          <div class="avada-row">

            <nav id="nav" class="nav-holder">

              <div role="navigation" class="navbar navbar-default">

                <div class="container-fluid">

                  <div class="navbar-header">
                  
                    <button data-target=".navbar-collapse" data-toggle="collapse" class="navbar-toggle" type="button"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button>
<span class="navbar-brand" href="#">Menu</span>
                  </div>

                  <div class="navbar-collapse collapse">

                    <ul class="nav navbar-nav">

					<li><a href="/">Journal Home</a></li><span class="menu-line">|</span>
                        <li><a href="../aims/">Aims and Scopes</a></li><span class="menu-line">|</span>
                        <li><a href="../charges/">Article Processing Charges</a></li><span class="menu-line">|</span>
                        <li><a href="../guidelines/">Author Guidelines</a></li><span class="menu-line">|</span>
                        <li><a href="../board/">Editorial Board</a></li><br>
                        <li><a href="../volumes/">Past Volumes</a></li><span class="menu-line">|</span>
                        <li><a href="../current/">Current Volume</a></li><span class="menu-line">|</span>
                        <li><a href="../propose/">Propose a Special Topic</a></li><span class="menu-line">|</span>
                        <li><a href="../register/">Receive Updates</a></li><span class="menu-line">|</span>
                        <li><a href="../contact/">Contact Us</a></li>



                    </ul>

                  </div>

                  <!--/.nav-collapse -->

                </div>

                <!--/.container-fluid -->

              </div>

            </nav>

            </div>

          </div>
          <div class="clearfix"></div>

        </header>

      </div>

    </div>
<div class="clearfix"></div>
  </div>

  <div class="slider">

  <div class="container">

  <div class="row"><div class="col-lg-12"><img class="img2" src="../images/header.png" alt="img"></div></div>

  </div>

  </div>

<div class="container">
  <div class="clearfix"></div>
  <div class="row">

  <div class="col-lg-12 text">
  
<div align=center>
<div class="table">

    <table class=MsoTableGrid border=0 cellspacing=0 cellpadding=0 style='border:none; width: 100%'>
         <tr>
                <td>Volume 1, Year 2014 - Pages 11-21</td>
                <td align="right"><a href="PDF/002.pdf">View PDF (Full-text)</a></td>
        </tr>
         <tr>
                <td>DOI: 10.11159/jacr.2014.002</td>
                <td align="right"><a href="#references">Linked References</a></td>
        </tr>
		<tr>
		<td colspan="2">ISSN: 2368-6677</td>
		</tr>
     </table>
     
</div>
</div>

<br>

<p align="center" style="font-size:22pt;">Terrain Roughness Identification for High-Speed UGVs</p>

<p align="center">

    <strong>Graeme N. Wilson, Alejandro Ramirez-Serrano</strong>
    
        <br>University of Calgary, 2500 University Dr NW, Calgary, Canada T2N 1N4
	    <br>gnw.wilson@gmail.com; aramirez@ucalgary.ca
        
</p>
    

<p align="justify"><i><strong>Abstract- </strong>
High-speed
navigation of autonomous Unmanned Ground Vehicles (UGVs) in rough unknown
terrains requires the detection and identification of the terrain in order to
make effective navigation decisions. This paper investigates a geometrical
approach to identifying terrain based on its roughness using the terrain
elevations from a point cloud generated using a 3D camera. This roughness,
called the Roughness Index (RI), is used to identify different terrains by
overlaying the terrain with a grid map and using the standard deviation of the
point cloud elevations in each grid cell. The experimental testing and results
of this terrain identification technique are presented as determined from field
experiments using an experimental UGV test platform on rough outdoor terrains.</i></p>

<p align="left"><i><strong>Keywords:</strong></i> Terrain classification, Unmanned ground
vehicles, Terrain identification, Terrain roughness detection</p>

<p>&nbsp;</p>
<p align="justify">  &copy; Copyright 2014 Authors - This is an Open Access article published under the <a href="http://creativecommons.org/licenses/by/3.0" target="_blank">Creative Commons Attribution License terms</a>. Unrestricted use, distribution, and reproduction in any medium are permitted, provided the original work is properly cited.</p>

<p>&nbsp;</p>

<p>
    Date Received: 2014-05-26 <br />
    
    Date Accepted: 2014-09-04  <br />
    
    Date Published: 2014-10-14
</p>

<img src="../images/line.png" width="100%;" height="1" />
<h2>1. Introduction</h2>

<p align="justify" style="text-indent:19.85pt;">Unmanned Ground Vehicles (UGVs) are becoming increasingly
prevalent in everyday life as these complex systems are being used in
applications including surveillance, military, law enforcement, industrial
hauling, and search and rescue. In order for these systems to navigate
effectively in any environment they must be able to detect the terrain and
react accordingly. When traveling at high speeds sudden changes in terrain
characteristics, without modification of UGV navigation behaviour, may damage
the vehicle due to excessive terrain interaction forces. In order to avoid such
occurrences techniques for predicting the terrain the UGV will encounter are
essential to allow for navigation decisions to be made in advance of the
vehicle physically encountering the terrain. This paper investigates the
challenge of predictive terrain identification to perform navigation decisions
for high-speed UGVs.</p>

<h4>1.1.Related Work</h4>

<p align="justify" style="text-indent:19.85pt;">Methods for the identification of terrain for the purpose of
traversability analysis fall into three main categories as identified by
Papadakis [1]: i) proprioceptive, ii) appearance
based, and iii) geometry based. Proprioceptive based techniques such as those
proposed by Sadhukhan [2], Brooks et al. [3], Weiss et al. [4], and DuPont et al. [5] have used frequency domain vibration
information measured from UGV mounted accelerometers along with machine
learning techniques to classify terrain into discrete terrain types (e.g.
grass, gravel, dirt). These works noted that the vibration measurements used to
classify terrain changed with vehicle speed for the same terrain making the
classification techniques speed dependent. To address this speed dependency for
a car type vehicle work by Ward and Iagnemma measured the un-sprung mass
acceleration and used a quarter car model, along with the speed of the vehicle,
to estimate the spatial profile as an input to a Support Vector Machine (SVM)
terrain classifier [6]. In a similar approach by Collins and
Coyle four one degree of freedom suspension elements were considered attached
to a rigid body, with linear vertical velocity, pitch rate, and roll rate of
the vehicles body sensor readings being used to estimate the spatial terrain
profile as an input to a Neural Network (NN) classifier [7]. </p>

<p align="justify" style="text-indent:19.85pt;">The problem with these approaches is that proprioceptive
terrain identification techniques are limited to reactive classification of
terrain, which means that sudden terrain changes when the vehicle is traveling
at high-speed may damage the vehicle before it can alter its navigation
behaviour. Additionally, these works all focused on terrain classification into
discrete terrain classes. Terrain classes such as dirt, grass, and gravel
provide no specific measure of traversability other than a class label (e.g.
knowing one terrain is grass and another is gravel provides no inherent
information about which terrain can be travelled on at a higher speed without
further knowledge), which means that further <i>a priori</i> knowledge of the
traversal characteristics for each terrain type must be predetermined or
learned by a machine learning algorithm. For large numbers of terrain classes
this is a significant and time consuming challenge, which is further
complicated since vehicles with different dynamics will have different terrain
traversability characteristics.</p>

<p align="justify" style="text-indent:19.85pt;">Appearance based techniques identify terrain predictively,
providing a solution to the problem of the reactive nature of proprioceptive
techniques. One approach to appearance based terrain identification is to perform
binary classification whereby terrain is identified as either traversable or
non-traversable [8]-[11]. The approaches by Shneiera
et al. in [8] and Thrun et al. in [9] were in fact a hybrid approach which
used geometric sensors to identify nearby non-traversable features with an
algorithm identifying similar appearing non-traversable regions in camera
images for longer range terrain prediction. Kim et al. took a different
approach by training a visual classifier to identify non-traversable regions
through a hand labelled training set [10]. The most recent approach by Milella et
al. uses radar to detect ground and non-ground areas, the results being used to
train a visual classifier to detect these binary classes [11]. The problem with binary approaches is
that the degree of traversability is not determined (e.g. pavement and gravel
are both traversable, but the approach does not identify pavement as more
traversable). </p>

<p align="justify" style="text-indent:19.85pt;">This need for more specific terrain type identification has
led to multi-class based terrain identification techniques. Visual data from a
camera image has been used to train machine learning techniques such as SVMs,
Extreme Learning Machines (ELM), NNs, and Bayesian classifiers [12]-[18]. Work by Abbas et al. used
colour and texture features along with a SVM to classify six terrain types with
up to 97% accuracy. Texture only features were used by Filitchkin and Byl for
terrain classification on Little Dog using an SVM classifier with up to 95%
accuracy for six terrain types [16]. A comparison of ten different
approaches for determining colour/texture features along with the comparison of
ELM, SVM, and NN machine learning techniques on five terrain types lead to the
determination by Zou et al. that the Joint Composite Descriptor (JCD) using ELM
produced the best terrain classification with up to 99% accuracy [13]. This JCD was developed in work by
Zagoris et al. [19]. Komma et al. performed Bayesian
classification on six terrain types with accuracy of up to 95% [14]. Bayesian classification was also done
by Kim et al. who went beyond terrain classification by using classified
terrains to estimate the friction coefficient of the ground from known terrain
type friction coefficient values [15]. A hybrid approach to visual
classification used by Brooks and Iagnemma trains a vibration classifier using
an SVM classifier with hand-labelled data, then these vibration classifications
are used to train a visual feature based (colour and texture) SVM classifier in
a self-supervised manner [17]. Another hybrid approach uses random
forests decisions trees (RFDT) to classify terrains independently based on
visual texture information and LIDAR data; these independent classifications
are then fused to produce classification rates up to 94% accurate on four
different terrain types [18].</p>

<p align="justify" style="text-indent:19.85pt;">While multi-class classification allows for the
discrimination of different terrain types to enable variable navigation
behaviour, there is still no specific knowledge relating to the level of
traversability without further information. For these classes a method of
determining the ideal navigation behaviour for each class label would either
need to be trained or previously known for the specific UGV dynamics.</p>

<p align="justify" style="text-indent:19.85pt;">Geometric approaches can address the issue of recognizing
specific traversability levels, although not all methods take this approach. In
the most common case geometric approaches identify obstacles using a point
cloud of the terrain elevations for detection of both positive and negative
features [20]-[22]. Another geometric approach
by Lu et al. used a 2D laser line stripper to extract spatial frequency and
texture information about the terrain to perform four class classification of
the terrain with over 90% accuracy [23]. While these approaches perform well,
they still do not identify the level of traversability for non-obstacle terrain
areas. </p>

<p align="justify" style="text-indent:19.85pt;">An example of a geometric technique that does address the
level of traversability is an approach by Broggi et al. that provides a method
for detecting the slope of the terrain, as well as obstacle detection, through
fitting a terrain to a B-spline surface [24]. This slope estimation provides an
explicit geometric measure of the terrain which is useful as a traversability
metric for preventing occurrences such as rollovers.</p>

<p align="justify" style="text-indent:19.85pt;">While slope is an important measure of terrain for
determining stability of the vehicle, another important aspect is to be able to
assess the terrain for its roughness such that the UGV will have a
traversability metric that can be used to control the speed of the vehicle (in
order to prevent excessive forces on rough terrains). Bellone et al. identifies
a method of detecting the normal vector of local surfaces from a point cloud
and using these normal vectors to estimate the local unevenness of the terrain [25]. This unevenness measure provides a
relative score of the traversability level of the terrain. With such an
approach the disadvantage is that a local normal vector representation of the
terrain requires the fitting of local planes which essentially produces a
smoothing effect on the data (i.e. local variations in the point cloud are
replaced with a smooth plane). Although the local unevenness calculation method
from [25] provides a method of measuring
variability of the neighbouring normal vectors, essential original geometric
point cloud information may have been lost from the fitting of the planes. A
method that avoids this potential loss of geometric information is proposed by
El-Kabbany and Ramirez-Serrano in [26] and improved by Wilson et al. in [27]. This method identifies terrain
roughness through the variance of the point elevations in a point cloud.</p>

<p align="justify" style="text-indent:19.85pt;">The method of terrain identification through geometric based
roughness identification proposed by El-Kabbany and Ramirez-Serrano in [26] and improved by Wilson et al. in [27] provides a measure of the level of
traversability of terrain and is a promising technique. The work in [26] and [27] provides the theoretical basis for this
terrain identification technique; however, this work does not fully investigate
the challenges of implementing such a technique on a real-world UGV platform,
not does it provide experimental testing and results of this technique
operating on a moving UGV in typical outdoor terrains.</p>

<p align="justify" style="text-indent:19.85pt;">This paper will develop metrics for determining the required
point density of the point cloud for calculating the terrain roughness for the
technique developed in [27]. Specifically this work will contribute
a novel measure of determining the minimum number of points from a point cloud
for calculating an effective roughness identification, an experimental method
of selecting an appropriate grid cell size based on this minimum point
threshold, and (for the first time) real-world experimental testing of this
roughness identification method on a UGV travelling under field conditions in
typical rough outdoor terrains.</p>

<h2>2. Theory</h2>

<p align="justify" style="text-indent:19.85pt;">Traversing a given <i>a priori</i> unknown terrain
effectively with a UGV requires the perception of the terrain in front of the
UGV. In this article this is accomplished through geometric perception of the
terrain using a range sensor (e.g. stereo camera, 3D laser scanner) to produce
a point cloud; experimental tests in this article used a MESA SwissRanger
SR4000 3D camera. As a 3D point cloud itself is not directly useful for
navigation decision making, this data must be processed to identify the terrain
based on its geometrical properties. For this purpose the Roughness Index (RI)
was developed. The RI is used to identify the perceived roughness of a terrain
using a 3D point cloud; the RI is defined as follows:</p>

<div class="eqn">
<img src="002_files/image001.png" class="img">
</div>
<div class="eqn-number">(1)</div>
<br>


<p align="justify">where <img src="002_files/image002.png">is
the sample standard deviation of the point elevations for a sample of size <img src="002_files/image003.png">, <img src="002_files/image004.png">is
a point elevation in the sample, <img src="002_files/image005.png">is the sample mean of the
point elevations, and <img src="002_files/image006.png">is the ground clearance of
the UGV.</p>

<p align="justify" style="text-indent:19.85pt;">The reason for the inclusion of the ground clearance <img src="002_files/image006.png">in Equation (1) is for the comparison of roughness
relative to the capabilities of the UGV. While mathematically the RI has a
range of <img src="002_files/image007.png">,
where 0 is a perfectly smooth terrain and <img src="002_files/image008.png">is
the roughest possible terrain, in practice it can be generally visualized that
any terrain with <img src="002_files/image009.png">is
smooth, while any terrain with <img src="002_files/image010.png">is
rough. The selection of 1<img src="002_files/image011.png">as rough terrain is arbitrary,
though mathematically it means that ~32% of the terrain point elevations are at
least one ground clearance greater than the mean (which is a significant
elevation change).</p>

<p align="justify" style="text-indent:19.85pt;">To demonstrate how the RI works a simulated example of a UGV
identifying a sigmoid terrain is presented. In this example the ground
clearance <img src="002_files/image006.png">of the vehicle was set to <img src="002_files/image012.png">,
while the terrain elevation change was <img src="002_files/image013.png">.
The surface of the sigmoid terrain being identified is shown in Figure 1, while the sigmoid terrain
profile is compared to the vehicle in Figure 2.</p>

<figure>
<img src="002_files/image014.jpg" class="img"/>

<figcaption>
Figure 1. Sigmoid surface</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image015.jpg" class="img"/>

<figcaption>
Figure 2. Sigmoid compared to UGV</figcaption>
</figure>
<br>


<p align="justify" style="text-indent:19.85pt;">To obtain a point cloud that represented this terrain 200
random points were placed on the surface of the sigmoid (Figure 3&amp; Figure 4) and from these the RI was
calculated. For these points the mean terrain point elevation was <img src="002_files/image016.png">and
the RI was <img src="002_files/image017.png">.
From these numbers it can be seen that a terrain with an <img src="002_files/image010.png">would
be quite rough, supporting the proposal that a value of 1 can be considered
rough terrain for visualization purposes.</p>

<h2>3. Implementation</h2>

<p align="justify" style="text-indent:19.85pt;">When implementing the RI for the purpose of terrain
identification on a UGV one possibility is to use the entire point cloud to
calculate a single RI for the entire area being captured by the 3D camera. The
problem with this is that different areas of the terrain that are being
captured may have dramatically different roughness. In the case of the MESA
SwissRanger SR4000 the range of the camera is ~10m; this is a long distance
where roughness may not be uniform. To improve the terrain identification the
terrain can be divided into a 2D grid map where the dimensions are the
horizontal distance in front of the camera, and the horizontal distances to the
left and right of the camera. For each grid cell the RI can be calculate
individually using the mean of the terrain elevation points within each cell.</p>

<figure>
<img src="002_files/image018.jpg" class="img"/>

<figcaption>
Figure 3. Point cloud</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image019.jpg" class="img"/>

<figcaption>
Figure 4. Point cloud: side view</figcaption>
</figure>
<br>

<p align="justify" style="text-indent:19.85pt;">For this 2D grid approach to implementing the RI it is
important to take into account the number of terrain elevations points that are
sampled in each grid cell. Since the RI is calculated as the sample standard
deviation of the terrain point elevations it is important that this sample
standard deviation be representative of the population standard deviation of
the grid cell. For this purpose assume that the terrain point elevation
population follows a normal distribution in each grid cell. Since each grid
cell contains a sample of the terrain point elevation population consider the
t-distribution that describes the distribution shape as a function of the
sample size. As the sample size approaches <img 
src="002_files/image008.png">the
t-distribution is equal to the normal distribution, and therefore at a
sufficiently large sample size the t-distribution is a good approximation of
the normal distribution. A common arbitrarily selected value for this
approximation is a sample size of 30 [28]. Therefore in this article it is assumed
that if the sample size of the terrain elevation points in a grid cell is <img 
src="002_files/image020.png">then
the sample standard deviation is considered to be a sufficient approximation of
the population standard deviation. In the implementation of the RI in a 2D grid
map any cell with less than 30 points is labelled as invalid.</p>

<p align="justify" style="text-indent:19.85pt;">Given that it is assumed that <img 
src="002_files/image020.png">terrain
elevation points are needed in a grid cell for it to be valid, it is important
to consider the size of the grid cells. If the grid cells are made too small
most of the grid cells will have <img 
src="002_files/image021.png">terrain
elevation points and will be invalid. On the other hand, if the grid size is
too large then smaller details about the terrain will be lost. It is therefore
important to select an appropriate grid cell size based on the cameras
resolution. To observe the effect of grid size on the RI grid, consider the
terrain presented in Figure 5. Using a SR4000 3D camera a
point cloud of the terrain was obtained (Figure 6). </p>

<p align="justify" style="text-indent:19.85pt;">From the point cloud in Figure 6, RI grids for various grid
sizes were calculated. These grid sizes were <img
src="002_files/image022.png">,
<img 
src="002_files/image023.png">,
<img 
src="002_files/image024.png">,
<img 
src="002_files/image025.png">,
and <img 
src="002_files/image026.png">as
shown respectively in Figure 7through Figure 11. </p>

<figure>
<img src="002_files/image027.jpg" class="img"/>

<figcaption>
Figure 5. Complex terrain</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image028.jpg" class="img"/>

<figcaption>
Figure 6. Complex terrain point cloud</figcaption>
</figure>
<br>

<p align="justify" style="text-indent:19.85pt;">Observing Figure 7, that has the smallest grid
size, it is clear that due to the point density of the camera there are limited
areas of the image which have <img 
src="002_files/image020.png">points;
therefore, other than a couple high roughness obstacles (trees) only about 1 to
<img 
src="002_files/image029.png">of
the terrain has any RI associated with it. In Figure 8, with a <img 
src="002_files/image023.png">grid
size, the range at which there is RI information has been extended to about 1.5
to <img 
src="002_files/image030.png">,
and the individual obstacles (trees) are still clearly visible. When the grid
size reaches <img 
src="002_files/image024.png">in
Figure 9the trees have begun to be
lumped together into larger areas of high RI, though at the same time the
patches of trees are still separated into two areas. This grid size has
extended the range of RI identified areas to about 2.5 to <img 
src="002_files/image031.png">.
When the grid size is increased yet further to <img 
src="002_files/image032.png">as
shown in Figure 10the trees have become a
single area of high roughness and all fine details have been lost. The
advantage to this grid size is that the range of the RI grid has been increased
to about <img 
src="002_files/image033.png">.
With the largest grid (Figure 11) it can be seen that the RI
scores have become generalized and there are no areas which have less than a
0.2 RI score. With this large grid size there are no fine details remaining
about the terrain; however, the range of areas with RI scores is the largest
(extending the full 5<i>m</i>). </p>

<p align="justify" style="text-indent:19.85pt;">From Figure 7to Figure 11it can be seen that it is
important to have a compromise between RI grid range and the resolution of the
RI grid. If the grid size is too small there will be very few areas with an RI
since <img 
src="002_files/image021.png">points
fall in the majority of the grid cells. If the grid cell size is too large fine
details about the terrain are lost, and the areas that do exist become more
generalized as they are taking the standard deviation of points over a larger
area. For the purpose of the testing in this article a grid cell size of 0.2<i>m</i>
was selected.</p>

<figure>
<img src="002_files/image034.jpg" class="img"/>

<figcaption>
Figure 7. Grid size 0.05m</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image035.jpg" class="img"/>

<figcaption>
Figure 8. Grid size 0.1m</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image036.jpg" class="img"/>

<figcaption>
Figure 9. Grid size 0.2m</figcaption>
</figure>
<br>
<figure>
<img src="002_files/image037.jpg" class="img"/>

<figcaption>
Figure 10. Grid size 0.5m</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image038.png" class="img"/>

<figcaption>
Figure 11. Grid size 1.0m</figcaption>
</figure>
<br>

<h2>4. Experimental Platform</h2>

<p align="justify" style="text-indent:19.85pt;">For the experimental testing of the RI in outdoor terrains
on a moving UGV an experimental test platform had to be developed. This custom
test platform is shown in Figure 12. </p>

<figure>
<img src="002_files/image039.jpg" class="img"/>

<figcaption>
Figure 12. Experimental test platform</figcaption>
</figure>
<br>

<p align="justify" style="text-indent:19.85pt;">This vehicle was custom made for the AR<sup>2</sup>S
Laboratory running a multitude of sensors for terrain identification and
vehicle state estimation. The state of the vehicle (position, velocity,
orientation) is estimated using an IMU, GPS, and wheel encoders running various
algorithms including a Kalman filter for positioning data. The SwissRanger
SR4000 mounted on the front of the vehicle is the 3D camera which captures the
point cloud. The Arduinos handle the motor control and the sensor data acquisition
while the Shuttle PC collects, processes, and stores the experimental data. The
UGV was driven by remote control with the XBee wireless transmitter receiving
the motion commands. This vehicle had a ground clearance of <img
src="002_files/image040.png">.</p>

<h2>5.
Experimental Testing and Results</a></h2>

<p align="justify" style="text-indent:19.85pt;">During the experimental testing the UGV was driven at a
speed of ~1.5m/s. During the testing the point cloud of the terrain was
captured and stored in real time along with the vehicle state estimates in 10
to <img 
src="002_files/image041.png">tests. The UGV was driven through a
variety of terrains including roots, pavement, gravel, and grass (Figure 13to Figure 16). </p>

<p align="justify" style="text-indent:19.85pt;">After the data was gathered it was processed in the lab to
produce the RI in a graphical RI grid map. The processing time of the point
clouds for each run into RI grids took approximately <img 
src="002_files/image042.png">of
the time each experiment was run (i.e. a 25s test run took 5s to process and
plot). This means this terrain identification technique is suitable for
real-world applications since it is able to run in real-time. The results for
each of the terrains are shown below (Figure 17to Figure 20). </p>

<p align="justify" style="text-indent:19.85pt;">From Figure 17through Figure 20it can be seen that the Root
terrain (Figure 17) is the roughest RI grid (as
expected), while the other three terrains are more similar in appearance. It
can be noted that the pavement (Figure 18) and gravel (Figure 19) terrains are almost
identical in appearance, which is to be expected since they are both relatively
smooth and hard surfaces. It should be mentioned that especially in the gravel
terrain there are some isolated areas of high roughness. These areas are
attributed to artifacts introduced by the parking lot lighting. It was noticed
that streetlights caused errors in the SwissRanger SR4000 cameras point cloud;
presumably the wavelength of the light being output by the lights is the same
as that of the SR4000's TOF sensors. The grass terrain (Figure 20) was slightly different than
the pavement and gravel, having areas of moderate roughness (RI<img 
src="002_files/image043.png">0.5).
This is because the grass, instead of the ground underneath, is being detected
by the SR4000 and the point cloud is producing a rougher appearing terrain than
actually exists. This is an issue with all current sensors and deformable
terrain/vegetation. Current sensor technology and techniques have a very
difficult time dealing with obstructions and terrain such as tall grass. </p>

<figure>
<img src="002_files/image044.jpg" class="img"/>

<figcaption>
Figure 13. Root terrain</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image045.jpg" class="img"/>

<figcaption>
Figure 14. Pavement terrain</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image046.jpg" class="img"/>

<figcaption>
Figure 15. Gravel terrain</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image047.jpg" class="img"/>

<figcaption>
Figure 16. Grass terrain</figcaption>
</figure>
<br>

<p align="justify" style="text-indent:19.85pt;">Addressing the most dynamic terrain again, the root terrain
(Figure 21), observe a comparison of
different areas of the terrain in Figure 22. The first area labelled Area
1 corresponds to a large horizontal root. As expected, in the RI grid this is
detected as a feature. Area 2 is a large wide collection of roots that is also
detected properly in the RI grids as a large area of high roughness. Finally,
Area 3 is a smoother area of dirt that is also correctly identified in the RI
grid. From this it is concluded that the RI is performing properly and
correctly identifying areas of high and low roughness.</p>

<figure>
<img src="002_files/image048.jpg" class="img"/>

<figcaption>
Figure 17. Root RI grid</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image049.jpg" class="img"/>

<figcaption>
Figure 18. Pavement RI grid</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image050.jpg" class="img"/>

<figcaption>
Figure 19. Gravel RI grid</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image051.jpg" class="img"/>

<figcaption>
Figure 20. Grass RI grid</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image052.jpg" class="img"/>

<figcaption>
Figure 21. Labeled root terrain</figcaption>
</figure>
<br>

<figure>
<img src="002_files/image053.jpg" class="img"/>

<figcaption>
Figure Figure 22. Labeled RI grid</figcaption>
</figure>
<br>

<h4>5.1. Discussion</h4>

<p align="justify" style="text-indent:19.85pt;">The results in Section 0 demonstrate the RI effectively
identifying terrain for a UGV traveling in typical outdoor terrain. In
comparison to proprioceptive techniques such as in [4]-[6]this technique is capable of
predicting upcoming terrains. This allows for a UGV to make navigation
decisions using the predicted terrain roughness before physically encountering
the terrain, preventing dangerous vehicle-terrain interaction forces. Existing
predictive techniques that identify traversable and non-traversable terrains in
[8]-[11]do not provide the same level
of detail as the RI and allow only for navigation decisions regarding where not
to travel. As seen in the results shown in this paper terrain is identified
with varying levels of roughness meaning a UGV can make more precise navigation
decisions. These precise navigation decisions could involve selecting vehicle
speed as a function of the RI (to prevent damage on high roughness areas, and
allow for fast travel on low roughness areas), thus allowing for the vehicle to
optimize a path across the terrain that would be as fast and safe as possible.</p>

<p align="justify" style="text-indent:19.85pt;">Techniques exist for identifying classes of traversable
terrains in the form of multi-class classification approaches [12]-[18]. While these approaches could
also enable more precise navigation decisions the problem is that identifying
that terrain is of one class or another does not, considered alone, provide any
information about the relative traversability of the terrain. For example,
knowing the terrain type is either grass or gravel with no additional
information does not assist in determining which terrain is more traversable;
however, knowing one terrain has a RI of 0.4 and another has a RI of 0.7
clearly indicates that it would be easier to traverse the terrain with the
lower roughness of 0.4. For multi-class classification approaches significant
additional effort must be made to characterize each terrain class and determine
the relative navigability.</p>

<p align="justify" style="text-indent:19.85pt;">There do exist other geometric approaches to terrain
identification that provide an explicit relative measure of the terrain's
traversability. For example the work in [24] presented a method of estimating the
terrain slope. This approach serves a different purpose to the RI presented in
this paper; it can be used to determine the stability of the UGV as it
traverses terrain. What this method of slope prediction is not able to provide
is a method of predicting the relative measure of terrain interaction forces.
For high RI the higher roughness would cause higher vehicle-terrain interaction
forces, while lower RI would cause smaller forces. This information can be used
to determine speed of the vehicle for the navigation behaviour. </p>

<p align="justify" style="text-indent:19.85pt;">Another approach for geometric relative traversability has
also been developed in [25]. This approach identified the normal
vector for local surfaces of the terrain, and a comparison of neighbouring
normal vectors was used to calculate an unevenness measurement of the terrain.
While this is basically another approach to roughness identification of the
terrain, the method of calculating unevenness from a comparison of normal
vectors of the local surfaces causes the loss of geometric information for the
terrain. These unevenness measures provide only a relative comparison of the
terrain unevenness when compared with respect to another unevenness measure.
The RI, on the other hand, preserves key geometric information about the
terrain. Given that the RI is essential a measure of the standard deviation of
the points within a grid cell, this standard deviation (along with an assumed
standard distribution of points) can be used to estimate key terrain
characteristics such as probabilistic maximum step height of the terrain
(through estimating maximum/minimum expected point elevations for the specific
value of the standard deviation). Potential applications for this maintained
geometric information include predictive explicit terrain-vehicle interaction
force estimation through using the probabilistic step height as an input to a
dynamics model of the UGV.</p>

<p align="justify" style="text-indent:19.85pt;">This paper has demonstrated that the RI is capable of
providing predictive measure of terrain traversability with calculations
performed in real-time which in future work will enable a UGV to make effective
navigation decisions in advance of physically encountering potential dangerous
terrain. It has also demonstrated that is can effectively detect the relative
traversability of the terrain for use in navigation decision making while
maintaining geometric information pertaining to the standard deviation of the
point distribution within each grid cell (potentially useful in applications of
predicting terrain-interaction forces). </p>

<p align="justify" style="text-indent:19.85pt;">While this technique of terrain identification using the RI
has presented many advantages, there are aspects of the technique that need to
be improved or supplemented by another technique. For example, the RI does not
provide information about the terrain slope. When making navigation manoeuvres
vehicle stability is important and additional information about terrain slope
is necessary to supplement the terrain information provided by the RI. Additionally,
the RI is dependent on a high density point cloud of the environment. Typical
geometric sensors currently have either limited range (e.g. time of flight
cameras), have significant resolution limitations as range increases (e.g.
laser scanners), or have substantially increasing error as range increases
(e.g. stereo camera, error is proportional to square of distance). Further
development of sensor technologies which provide a long range dense point
cloud, or methods of extrapolating short range point clouds to longer ranges,
will be necessary for high-speed travel since the UGV must at least be able to
have time to come to a complete stop after dangerous terrain features are
detected (e.g. stopping distance for a typical car is 55m at 96km/h [29]). This technique also runs into
limitations in terrains with features such as dense vegetation where the 3D
point cloud of the terrain is prevented from detecting the true surface of the
terrain and instead picks up the features of the vegetation. Sensor
technologies for detecting the true surface of the terrain through obstructions
(such as vegetation) will need to be developed. Finally, the RI also considers
all terrain is rigid. Deformable terrains are not accounted for in the RI, and
it will be an area for further investigation to determine methods to account
for this deformability.</p>

<h2>6.
Conclusion</h2>

<p align="justify" style="text-indent:19.85pt;">This paper presented a geometrical
terrain identification approach, the Roughness Index (RI), that identified
terrain based on the roughness of the terrain using the point cloud of a 3D
camera sensor. Techniques for implementing the RI on real world terrains using
a grid map were investigated. Comparisons of different grid size selections and
their effect on the RI grid map were discussed. It was found that as the grid
size was increased the effective range of the 3D camera was increased (due to
the sparsity of points at longer ranges); however, this range increase came at
the cost of losing terrain details. It was therefore concluded that a
compromise must be selected between RI grid range and the detailed resolution
of the grid.</p>

<p align="justify" style="text-indent:19.85pt;">This technique was also implemented on an
experimental UGV platform for real-world testing. During the testing the RI
was computed for a variety of terrains (grass, gravel, pavement, roots). It was
found that the RI performed well at correctly identifying areas of high and low
roughness. It was also concluded that the algorithm was fast enough to run in
real time for high-speed vehicles, meaning it can be used in real-world
applications.</p>

<p align="justify" style="text-indent:19.85pt;">Further work planned in this area
includes expanding this roughness detection to account for terrain
deformability (the technique proposed here assumes all terrain is rigid), and
extrapolating terrain roughness to distant terrain using terrain appearance in
a camera image (since 3D point cloud generating sensors are either short range
or have low point density at long ranges), and methods to account for point
cloud obstructions (e.g. vegetation).</p>



<img src="../images/line.png" width="100&#37;" height="1" />
<H2><a name="references">References</a></H2>

<p>[1] P. Papadakis,
"Terrain traversability analysis methods for unmanned ground vehicles: A survey,"
<i>Eng. Appl. Artif. Intell.</i>, vol. 26, no. 4, pp. 1373-1385, 2013. <a href="http://dx.doi.org/10.1016/j.engappai.2013.01.006" target="_blank">View Article</a></p>

<p>[2] D. Sadhukhan, "Autonomous ground
vehicle terrain classification using internal sensors," MIT Press, 2004. <a href="http://diginole.lib.fsu.edu/etd/2115/" target="_blank">View Article</a></p>

<p>[3] C. A. Brooks and K. Iagnemma,
"Vibration-Based Terrain Classification for Planetary Exploration Rovers," in <i>IEEE
Transactions on Robotics</i>, 2005, vol. 21, no. 6, pp. 1185-1191. <a href="http://dx.doi.org/10.1109/TRO.2005.855994" target="_blank">View Article</a></p>

<p>[4] C. Weiss, M. Stark, and A. Zell, "SVMs
for Vibration-Based Terrain Classification," in <i>Autonome Mobile Systeme</i>,
2007, pp. 1-7. <a href="http://dx.doi.org/10.1007/978-3-540-74764-2_1" target="_blank">View Article</a></p>

<p>[5] E. M. DuPont, C. A. Moore, E. G.
Collins, and E. Coyle, "Frequency response method for terrain classification in
autonomous ground vehicles," <i>Auton. Robot</i>, vol. 24, no. 4, pp. 337-347,
2008. <a href="http://dx.doi.org/10.1007/s10514-007-9077-0" target="_blank">View Article</a></p>

<p>[6] C. C. Ward and K. Iagnemma,
"Speed-independent vibration-based terrain classification for passenger
vehicles," <i>Veh. Sys. Dyn.</i>, vol. 47, no. 9, pp. 1095-1113, 2009. <a href="http://dx.doi.org/10.1080/00423110802450193" target="_blank">View Article</a></p>

<p>[7] E. G. Collins and E. J. Coyle,
"Vibration-Based Terrain Classification Using Surface Profile Input Frequency
Responses," in <i>IEEE Int. Conf. on Robot. and Autom.</i>, 2008, pp.
3276-3283. <a href="http://dx.doi.org/10.1109/ROBOT.2008.4543710" target="_blank">View Article</a></p>

<p>[8] M. Shneier, T. Chang, T. Hong, W.
Shackleford, R. Bostelman, and J. S. Albus, "Learning traversability models for
autonomous mobile vehicles," <i>Auton. Robots</i>, vol. 24, no. 1, pp. 69-86,
2008. <a href="http://dx.doi.org/10.1007/s10514-007-9063-6" target="_blank">View Article</a></p>

<p>[9] S. Thrun, M. Montemerlo, H. Dahlkamp,
D. Stavens, A. Aron, J. Diebel, P. Fong, J. Gale, M. Halpenny, G. Hoffmann, K.
Lau, C. Oakley, M. Palatucci, V. Pratt, P. Stang, S. Strohband, C. Dupont, L.
Jendrossek, C. Koelen, C. Markey, C. Rummel, J. Van Niekerk, E. Jensen, P.
Alessandrini, G. Bradski, B. Davies, S. Ettinger, A. Kaehler, A. Nefian, and P.
Mahoney, "Stanley&#8239;: The Robot that Won the DARPA Grand Challenge," <i>J.
F. Robot.</i>, vol. 23, no. 9, pp. 661-692, 2006. <a href="http://dx.doi.org/10.1002/rob.20147" target="_blank">View Article</a></p>

<p>[10] D. Kim, S. M. Oh, and J. M. Rehg,
"Traversability classification for UGV navigation: a comparison of patch and
superpixel representations," in <i>IEEE/RSJ Int.Conf. on Intel. Robots and
Systems</i>, 2007, pp. 3166-3173. <a href="http://dx.doi.org/10.1109/IROS.2007.4399610" target="_blank">View Article</a></p>

<p>[11] G. Reina and J. Underwood, "A
Self-learning Framework for Statistical Ground Classification using Radar and
Monocular Vision," <i>J. F. Robot.</i>, pp. 1-22, 2014. <a href="http://dx.doi.org/10.1002/rob.21512" target="_blank">View Article</a></p>

<p>[12] S. M. Abbas, A. Muhammad, S. A. Mehdi,
and K. Berns, "Improvements in Accuracy of Single Camera Terrain
Classification," in <i>IEEE Int. Conf. on Adv. Robot.</i>, 2013, pp. 1-6. <a href="http://dx.doi.org/10.1109/ICAR.2013.6766493" target="_blank">View Article</a></p>

<p>[13] Y. Zou, W. Chen, L. Xie, and X. Wu, "Comparison
of different approaches to visual terrain classification for outdoor mobile
robots," <i>Pattern Recognit. Lett.</i>, vol. 38, pp. 54-62, 2014. <a href="http://dx.doi.org/10.1016/j.patrec.2013.11.004" target="_blank">View Article</a></p>

<p>[14] P. Komma, C. Weiss, and A. Zell,
"Adaptive Bayesian Filtering for Vibration-based Terrain Classification," in <i>IEEE
Int. Conf. on Robotics and Automation</i>, 2009, pp. 3307-3313. <a href="http://dx.doi.org/10.1109/ROBOT.2009.5152327" target="_blank">View Article</a></p>

<p>[15] J. Kim, D. Kim, J. Lee, J. Lee, H. Joo,
and I. K. Member, "Non-contact Terrain Classification for Autonomous Mobile
Robot," in <i>IEEE Int. Conf. on Robotics and Biomimetics</i>, 2009, pp. 824-829. <a href="http://dx.doi.org/10.1109/ROBIO.2009.5420568" target="_blank">View Article</a></p>

<p>[16] P. Filitchkin and K. Byl, "Feature-based
terrain classification for LittleDog," in <i>IEEE/RSJ International Conference
on Intelligent Robots and Systems</i>, 2012, pp. 1387-1392. <a href="http://dx.doi.org/10.1109/IROS.2012.6386042" target="_blank">View Article</a></p>

<p>[17] C. A. Brooks and K. Iagnemma,
"Self-Supervised Terrain Classification for Planetary Surface Exploration
Rovers," <i>J. F. Robot.</i>, vol. 29, no. 3, pp. 445-468, 2012. <a href="http://dx.doi.org/10.1002/rob.21408" target="_blank">View Article</a></p>

<p>[18] S. Laible, Y. N. Khan, and A. Zell,
"Terrain classification with conditional random fields on fused 3D LIDAR and
camera data," in <i>European Conference on Mobile Robots</i>, 2013, pp.
172-177. <a href="http://dx.doi.org/10.1109/ECMR.2013.6698838" target="_blank">View Article</a></p>

<p>[19] K. Zagoris, S. a. Chatzichristofis, N.
Papamarkos, and Y. S. Boutalis, "Automatic Image Annotation and Retrieval Using
the Joint Composite Descriptor," in <i>14th Panhellenic Conference on
Informatics</i>, 2010. <a href="http://dx.doi.org/10.1109/PCI.2010.38" target="_blank">View Article</a></p>

<p>[20] C. Armbrust, T. Braun, T. Fohst, M.
Proetzsch, A. Renner, H. Schafer, B., and K. Berns, "Ravon - the robust
autonomous vehicle for off-road navigation," in <i>IARP International Workshop
on Robotics for Risky Interventions and Environmental Surveillance</i>, 2009,
pp. 1-28. <a href="http://agrosy.informatik.uni-kl.de/fileadmin/Literatur/Armbrust09.pdf" target="_blank">View Article</a></p>

<p>[21] J. Larson, M. Trivedi, and M. Bruch,
"Off-Road Terrain Traversability Analysis and Hazard Avoidance for UGVs," in <i>California
University San Diego Dept of Electrical Engineering</i>, 2011, pp. 1-7. <a href="http://cvrr.ucsd.edu/ece285/papers/traversability.pdf" target="_blank">View Article</a></p>

<p>[22] W. Wang, M. Shen, J. Xu, W. Zhou, and J.
Liu, "Visual traversability analysis for micro planetary rover," in <i>IEEE
International Conference on Robotics and Biomimetics</i>, 2009, pp. 907-912. <a href="http://dx.doi.org/10.1109/ROBIO.2009.5420494" target="_blank">View Article</a></p>

<p>[23] L. Lu, C. Ordonez, E. G. Collins, E.
Coyle, and D. Palejiya, "Terrain surface classification with a control mode
update rule using a 2D laser stripe-based structured light sensor," <i>Rob.
Auton. Syst.</i>, vol. 59, no. 11, pp. 954-965, 2011. <a href="http://dx.doi.org/10.1016/j.robot.2011.06.015" target="_blank">View Article</a></p>

<p>[24] A. Broggi, E. Cardarelli, S. Cattani,
and M. Sabbatelli, "Terrain mapping for off-road Autonomous Ground Vehicles
using rational B-Spline surfaces and stereo vision," in <i>IEEE Intel. Veh.
Symp</i>, 2013, pp. 648-653. <a href="http://dx.doi.org/10.1109/IVS.2013.6629540" target="_blank">View Article</a></p>

<p>[25] M. Bellone, A. Messina, and G. Reina, "A
new approach for terrain analysis in mobile robot applications," in <i>IEEE
International Conference on Mechatronics</i>, 2013, pp. 225-230. <a href="http://dx.doi.org/10.1109/ICMECH.2013.6518540" target="_blank">View Article</a></p>

<p>[26] A. El-Kabbany and A. Ramirez-Serrano,
"Terrain Roughness Assessment for High Speed UGV Navigation in Unknown
Heterogeneous Terrains," <i>Int. J. Inf. Acq.</i>, vol. 7, no. 2, pp. 165-176,
2010. <a href="http://dx.doi.org/10.1142/S0219878910002142" target="_blank">View Article</a></p>

<p>[27] G. N. Wilson, A. Ramirez-Serrano, M.
Mustafa, and K. A. Davies, "Velocity Selection for High-Speed UGVs in Rough
Unknown Terrains Using Force Prediction," in <i>5th Int. Conf. on Intel.
Robotics and App.</i>, 2012, pp. 387-396. <a href="http://dx.doi.org/10.1007/978-3-642-33515-0_39" target="_blank">View Article</a></p>

<p>[28] J. T. McClave and T. Sincich, <i>Statistics</i>,
11th ed. Pearson, 2009. <a href="http://books.google.ca/books?id=22VTLwEACAAJ&dq=Statistics+mcclave&hl=en&sa=X&ei=IGE9VNnJMo62yASEl4HIDQ&redir_esc=y" target="_blank">View Book</a></p>

<p>[29] Department for Transport and Driver and
Vehicle Standards Agency, "Typical Stopping Distances," <i>The Highway Code</i>,
2007. [Online]. Available:
https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/312249/the-highway-code-typical-stopping-distances.pdf.
[Accessed: 16-Aug-2014]. <a href="https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/312249/the-highway-code-typical-stopping-distances.pdf" target="_blank">View Article</a></p>

<div class="clearfix"></div>
  </div>
<div class="clearfix"></div>
  </div>
<div class="clearfix"></div>
  </div>

  </div>

  <div class="footer">

  <div class="container">

  <div class="col-sm-7 footer-link">

        <p><a href="http://avestia.com">Avestia Publishing</a></p>
        <p><a href="../register/">Subscribe to our Mailing List</a></p>
        <p><script>var refURL = window.location.protocol + "//" + window.location.host + window.location.pathname; document.write('<a href="http://avestia.com/feedback/?refURL=' + refURL+'">Feedback</a>');</script></p>
        <p><a href="../terms/">Terms of Use</a></p>
		<p><a href="../sitemap/">Sitemap</a></p>

      </div>
      <div class="col-sm-5 footer-txt">
        <p>Avestia Publishing, International ASET Inc. </p>
        <p>Unit No. 417, 1376 Bank St. </p>
        <p>Ottawa, Ontario, Canada </p>
        <p>Postal Code: K1H 7Y3</p>
        <p>Phone Number: 1-613-695-3040</p>

  </div>

  </div>

  </div>

</div>
<script src="../js/jquery.js"></script>
<script src="../js/bootstrap.js"></script>
</body>

</html>
